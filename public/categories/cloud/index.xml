<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cloud on ngaih.tech</title>
    <link>/categories/cloud/</link>
    <description>Recent content in cloud on ngaih.tech</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="/categories/cloud/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Adding a content delivery network and github actions to our static site</title>
      <link>/posts/cloudfront/</link>
      <pubDate>Wed, 05 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/posts/cloudfront/</guid>
      <description>In this blog post let us further improve our static site hosted on S3 bucket in AWS by using a content delivery network. We will also implement a continuous deployment feature for our site using github actions.
Content Delivery Network A CDN, or Content Delivery Network, is a network of servers distributed across different geographic locations that work together to provide fast and reliable delivery of internet content, such as images, videos, and web pages, to end-users.</description>
      <content>&lt;p&gt;In this blog post let us further improve our static site hosted on &lt;code&gt;S3 bucket&lt;/code&gt; in AWS by using a content delivery network. We will also implement a continuous deployment feature for our site using github actions.&lt;/p&gt;
&lt;h2 id=&#34;content-delivery-network&#34;&gt;Content Delivery Network&lt;/h2&gt;
&lt;p&gt;A CDN, or Content Delivery Network, is a network of servers distributed across different geographic locations that work together to provide fast and reliable delivery of internet content, such as images, videos, and web pages, to end-users.&lt;/p&gt;
&lt;p&gt;When a user requests a piece of content, the CDN automatically determines the best server to deliver the content from based on factors like geographic proximity, server load, and network availability. The content is then delivered to the user from the server that can provide the fastest and most reliable connection, which helps to reduce latency and improve overall website performance.&lt;/p&gt;
&lt;p&gt;Amazon CloudFront is a cdn offered by AWS and Cloudflare is also a popular cdn used by many sites.&lt;/p&gt;
&lt;h3 id=&#34;what-we-will-be-using&#34;&gt;What we will be using:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Route53: Domain Name Service of AWS&lt;/li&gt;
&lt;li&gt;CloudFront: Content Delivery Network of AWS&lt;/li&gt;
&lt;li&gt;Github Actions: Automation services provided by Github&lt;/li&gt;
&lt;li&gt;Certificate Manager: Generating certificates offered by AWS&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;certificate-manager&#34;&gt;Certificate Manager&lt;/h3&gt;
&lt;p&gt;Let us first create a SSL certificate for our domain so that we can use https when accessing our static files.
Since it&amp;rsquo;s fairly simple, we won&amp;rsquo;t go through steps by steps.
We just to click on request, enter the domain name that we will generate the certificate for, select a validation type, and since we use route53 we can click on create records in route53 for validating that we own the domain.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cdn/certificate.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;After validation, we will get certificate like the one above.&lt;/p&gt;
&lt;h2 id=&#34;cloudfront&#34;&gt;CloudFront&lt;/h2&gt;
&lt;p&gt;Go to cloudfront services in AWS. Click on &lt;code&gt;create distribution&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cdn/cloudfrontCreate.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the origin domain, enter the s3 static site domain. We get this information from the previous s3 bucket where we created our site. We can leave most of the default settings, but since I want to use https, I will check the redirect http to https in the viewer protocol policy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cdn/cloudfrontCreate1.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cdn/cloudfrontCreate2.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;In alternate domain name, we will enter our domain and select the certificate we have created before.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cdn/cloudfrontCreate3.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Then &lt;code&gt;create distribution&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cdn/cloudfrontCreate4.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let us make note of the ID, this will be required later when we set up github actions.&lt;/p&gt;
&lt;p&gt;Click the ID of the distribution and in details we can see the distribution domain name, also make note of this so that we can point our domain name to the cloud front distribution.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cdn/cloudfrontCreate5.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;After the distribution has been deployed, we can enter the distribution domain name and it will fetch our static site from the s3 bucket and cache them in the edge locations. We have now deployed our static site using a cdn and have improve the latency as well as reach of our site.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Next step, is to point our domain name to the cloud front distribution domain.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;route-53&#34;&gt;Route 53&lt;/h3&gt;
&lt;p&gt;We have hosted our domain name in a hosted zone in route53, due to its seamless integration with other aws services and to make use of alias feature.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Using alias for pointing to a cloudfront endpoint is native to AWS so it won&amp;rsquo;t work if you are using other DNS service providers like godaddy, namecheap etc.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Go to the hosted zone, click on our domain and &lt;code&gt;create record&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cdn/route53.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now create an A record, turn on alias and route traffic to cloudfront distribution and also enter the cloudfront domain.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/cdn/route531.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Create records&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Allow for the changes to propagate, after a few minutes, we can enter our url &lt;a href=&#34;https://ngaih.tech&#34;&gt;https://ngaih.tech&lt;/a&gt; and we will directed to our domain that is hosted in a cdn of cloudfront.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To update our site we have to upload new files to the s3 bucket and then since the old versions are probably cached in the cloud front distributions, we have to invalidate the cache so that the site will be refreshed when people visit the domain. Since our site is created using hugo and the code and static files are hosted on github, we can automate the process of deployment using github actions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;continuous-deployment&#34;&gt;Continuous Deployment&lt;/h2&gt;
&lt;p&gt;Since this part of the content is mostly unique to hugo and this blog, we will speed run through the steps since the reader is assumed to be more of expert level.&lt;/p&gt;
&lt;p&gt;Create a policy in aws and give it access to s3 objects and ability to invalidate cache.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Version&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2012-10-17&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Statement&amp;#34;&lt;/span&gt;: [
        {
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Sid&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ListObjectsInBucket&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Effect&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Allow&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Action&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s3:ListBucket&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Resource&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;arn:aws:s3:::ngaih&amp;#34;&lt;/span&gt;
        },
        {
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Sid&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AllObjectActions&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Effect&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Allow&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Action&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s3:*Object&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Resource&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;arn:aws:s3:::ngaih/*&amp;#34;&lt;/span&gt;
        },
        {
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Sid&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;InvalidateCache&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Effect&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Allow&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Action&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cloudfront:CreateInvalidation&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Resource&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Tie this policy to a user and generate access keys for programmatic accesss. We will use this user for github actions so that it can connect to our s3 bucket to perform uploads of files and invalidate cache.&lt;/p&gt;
&lt;p&gt;Enter the secret like AWS ACCESS KEY ID and AWS ACCESS KEY in the github actions secrets.&lt;/p&gt;
&lt;p&gt;Now create a github workflow&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Build and Deploy Hugo site to S3 and Cloudfront&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;on&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;push&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;branches&lt;/span&gt;: 
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;master&lt;/span&gt;
  
&lt;span style=&#34;color:#f92672&#34;&gt;jobs&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;build-and-deploy&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Build and Deploy&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;runs-on&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ubuntu-22.04&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;env&lt;/span&gt;: 
      &lt;span style=&#34;color:#f92672&#34;&gt;BUCKET&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ngaih&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#bucket name&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;REGION&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ap-south-1&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;DIST_ID&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;distribution ID&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#replace&lt;/span&gt;

    &lt;span style=&#34;color:#f92672&#34;&gt;concurrency&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;group&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;${{ github.workflow }}-${{ github.ref }}&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;steps&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;uses&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;actions/checkout@v3&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;with&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;submodules&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# Fetch Hugo themes (true OR recursive)&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;fetch-depth&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Fetch all history for .GitInfo and .Lastmod&lt;/span&gt;

      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Setup Hugo&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;uses&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;peaceiris/actions-hugo@v2&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;with&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;hugo-version&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;latest&amp;#39;&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;# extended: true&lt;/span&gt;

      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Build&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hugo&lt;/span&gt;

      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Configure AWS Credentials&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;uses&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;aws-actions/configure-aws-credentials@v2&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;with&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;aws-access-key-id&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;${{ secrets.AWS_ACCESS_KEY_ID }}&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;aws-secret-access-key&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;${{ secrets.AWS_SECRET_ACCESS_KEY }}&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;aws-region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;${{ env.REGION }}&lt;/span&gt;
      
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Copy files to production S3&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: |&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;          &lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;aws s3 sync public/ s3://${{ env.BUCKET }} --delete&lt;/span&gt;
      
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Invalidate cache&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: |&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;          aws cloudfront create-invalidation \
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;          --distribution-id ${{ env.DIST_ID }} \
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;          --paths &amp;#34;/*&amp;#34;&lt;/span&gt;          
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;We have basically a Continuous Deployment for our website and we will get automatic content update whenever we push our site to github.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
    </item>
    
    <item>
      <title>Using AWS Elastic Load Balancer and AutoScaling Group for high Scalability and Availability</title>
      <link>/posts/scalability/</link>
      <pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/posts/scalability/</guid>
      <description>In this blog post today, we will be implementing scalability and availabilty principles to this blog. We will use AWS Services, namely the AWS Elastic Load Balancer (ELB) and Auto Scaling Group to achieve our goal. This blog is powered by nginx and running on a single EC2 instance, so it is a perfect candidate for scaling and increasing its availability. Let us understand some key terms first, before we proceed:</description>
      <content>&lt;p&gt;In this blog post today, we will be implementing scalability and availabilty principles to this blog. We will use AWS Services, namely the &lt;code&gt;AWS Elastic Load Balancer (ELB)&lt;/code&gt; and &lt;code&gt;Auto Scaling Group&lt;/code&gt; to achieve our goal. This blog is powered by &lt;code&gt;nginx&lt;/code&gt; and running on a single &lt;code&gt;EC2&lt;/code&gt; instance, so it is a perfect candidate for scaling and increasing its availability. Let us understand some key terms first, before we proceed:&lt;/p&gt;
&lt;h4 id=&#34;availability&#34;&gt;Availability&lt;/h4&gt;
&lt;p&gt;Availabilty is the ability to provide continued access to a service to its end users while remaining operational. We can achieve availability in our services by running the services in two or more locations and being isolated from each other failures.&lt;/p&gt;
&lt;h4 id=&#34;scalability&#34;&gt;Scalability&lt;/h4&gt;
&lt;p&gt;Scalability refers to the abilty of the service to keep up with demand on its resources by adapting to the workload. This can be achieved by either scaling up vertically or horizontally. Vertical Scaling in context of servers, is the act of increasing the size of the resources like processor, memory or storage. In the same context, horizontal scaling is adding more servers and distributing workload among the servers.&lt;/p&gt;
&lt;h4 id=&#34;scaling-ngaihtech&#34;&gt;Scaling ngaih.tech&lt;/h4&gt;
&lt;p&gt;Since &lt;a href=&#34;http://ngaih.tech&#34;&gt;ngaih.tech&lt;/a&gt; is a static site running on nginx and the static site code is available on my &lt;a href=&#34;https://github.com/nga1hte/ngaih.tech&#34;&gt;repo&lt;/a&gt; we can easily replicate the running ec2 instance with very little effort and scale it.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/overview.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;img: overview of what our infrastructure will look like.&lt;/p&gt;
&lt;p&gt;Since we are going to create a template to launch our &lt;code&gt;EC2&lt;/code&gt; instances with configurations and userdata, let us first create a security group that will allow only http traffic to our &lt;code&gt;EC2&lt;/code&gt; instances and name it httpOnly.&lt;/p&gt;
&lt;p&gt;We will create a template with &lt;code&gt;Amazon Linux Image&lt;/code&gt; for our OS and use t.2 micro with default settings.
We use the following script in our userdata, which will basically clone &lt;a href=&#34;https://github.com/nga1hte/ngaih.tech&#34;&gt;ngaih.tech&lt;/a&gt; repository to our machine, install apache web server and then move our static site to the apache folder.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;yum update -y
yum install httpd git -y
systemctl enable httpd
systemctl start httpd
cd /tmp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; git clone https://github.com/nga1hte/ngaih.tech.git
sudo mv ./ngaih.tech/public/* /var/www/html/
rm -r /tmp/*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now that our lauch template is ready, let us create an &lt;code&gt;Auto Scaling Group&lt;/code&gt;. Auto Scaling Group enables us to automatically scale using some rules by using the launch template that we have just created.&lt;/p&gt;
&lt;p&gt;We create the group name and select the launch template we have just created.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/autoscaling.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;To support for availability I have selected two availability zones in my region of aws.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/availability.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;We will skip the next part of the setup, since we have not created a load balancer yet. We will come back later and attach a load balancer.&lt;/p&gt;
&lt;p&gt;Next we enter the number of instances that will run, and the amount of instances that we can scale up to.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Desired: The amount of instances that will run.&lt;/li&gt;
&lt;li&gt;Minimum: The minimum amount of instances that can run.&lt;/li&gt;
&lt;li&gt;Maximum: The amount of instances that we can scale to.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our desired capacity must be between the min-max range.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/scaling-min-max.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;In scaling, we will use the default Target Tracking Policy and metric of Average CPU utilisaton set to 50%.
This means that if the cpu use of all our instances cross 50% then we will add more instances to help with the load.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/scaling-policy.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can proceed to the next page and skip to step 7 since we are not going to use SNS and tags in this example.
After reviewing, let us create the scaling group.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/auto-scaling-group.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can also observe that the autoscaling group has created two instances from the template that we have created. We can enter the public IP of the instances to verify that our userdata script works.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/instances.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/site.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Auto Scaling Group&lt;/code&gt; will make sure that we always have two instances running and depending upon the CPU usage, will create more instances when average CPU usage is greater than 50%.&lt;/p&gt;
&lt;p&gt;We can enter also check the activity of the auto scaling group and see the activity history. In our activity history we can see the launching of two new instances.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/activity.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can also go to monitoring and observe the various metrics, like cpu usage, network in and out etc.&lt;/p&gt;
&lt;p&gt;Now that we have our instances ready it is now time to set up our load balancer. Go to the navigation pane and select &lt;code&gt;Load Balancers&lt;/code&gt; and create load balancer. Since we are handling http traffic we will use the &lt;code&gt;Application Load Balancer&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Create a name for the load balancer and leave the default settings, since our load balancer is going to be used on the internet traffic.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/loadBalancer.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Next, we select the availability zones where our ec2 instances resides in, and make sure to create a httpOnly security group for the load balancer since we are going to expose only the website to the public.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/load-securityGroup.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Next we have to create listeners and routing for our load balancers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Listener: Protocol and Port which the load balancer will listen.&lt;/li&gt;
&lt;li&gt;Routing: Where the packets are going to be forwarded.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/listener.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;We have to create a target group. Target group is where the traffic is going to be forwarded to, and in our case, the target group must consists of the ec2 instances that we have created in the autoscaling group.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/load-securityGroup.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Click on the create target group to create one for our instances. On the first page, you can just input the target group name and proceed to the next page. It is also worth mentioning that the health check route is what the load balancer will use to check if the instance is down and we need to terminate the instance to spring up another instance.&lt;/p&gt;
&lt;p&gt;On the next page, select our instances that are running and then click on &lt;code&gt;include as pending below&lt;/code&gt; to add our instances.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/pending-below.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Then click on create. Now go to the previous load balancer page and select the target group we have just created.&lt;/p&gt;
&lt;p&gt;We can now click on create load balancer.
Our load balancer has now been created.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/successfully-created.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here is the details of our load balancer.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/details-load-balancer.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Our load balancer has a dns name and that dns name is the endpoint that is exposed to the public. Any traffic that is send to the dns name will get routed and distributed to the instances that are in our auto scaling group and depending on the utilisation of the cpu of the instances, we will scale up and down. Since the instances are in two availability zones, we have also improved the availability of our website.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;DNS name: &lt;a href=&#34;http://balancerrr-1903341826.ap-south-1.elb.amazonaws.com/&#34;&gt;http://balancerrr-1903341826.ap-south-1.elb.amazonaws.com/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now that we have created our load balancer, we also have to attach our autoscaling group with our load balancer so that new instances can be connected to the load balancer target group automatically.&lt;/p&gt;
&lt;p&gt;Go to our scaling group and then go to load balancing, edit and attach the target group we have created and update.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/load-balance-edit.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/load-select-group.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;The security group of our ec2 instances are configured in such a way that they are still exposed to the internet and anyone who have the public ip address can connect to the individual instances. So let us modify the security group of the instances to allow only http traffic from the load balancer. Make sure to make the type http and port to 80.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/change-security-group.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;We just have to reference the security group of the load balancer in the source.
Now our ec2 instances can only be accessed through the load balancer.&lt;/p&gt;
&lt;p&gt;To check that our auto scaling group is working properly, I will enable ssh on our ec2 instances and perform a stress test.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/stress.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Stressing both the running instances let us check the monitoring from the the auto scaling group.
There is a spike in cpu utilisation above 50%&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/spike.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can see two new activity in the history&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/activities.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;And there are now four running instances in our scaling group.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/maxinstances.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now let me stop the stress test to see what happens when cpu usage goes down.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/scaling/termination.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can see that our servers scale down, to terminate the two instances since they are no longer needed.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There are other topics that we can go through like sticky sessions, other scaling polices, creating certificates for ssl for our load balancer to enable https and using our own domain for the load balancer but those are for another time.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
    </item>
    
    <item>
      <title>Hosting a static site in AWS S3 bucket</title>
      <link>/posts/statics3/</link>
      <pubDate>Tue, 28 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/posts/statics3/</guid>
      <description>Static Site A static site refers to a website that is made up of static HTML, CSS, and JavaScript files, which are delivered to the user&amp;rsquo;s web browser exactly as they are stored on the web server. In other words, the content of a static site is fixed and does not change dynamically in response to user input or other external factors.
Unlike dynamic websites, which rely on server-side processing to generate content on the fly, static sites are pre-built and require no server-side scripting or database access.</description>
      <content>&lt;h2 id=&#34;static-site&#34;&gt;Static Site&lt;/h2&gt;
&lt;p&gt;A static site refers to a website that is made up of static HTML, CSS, and JavaScript files, which are delivered to the user&amp;rsquo;s web browser exactly as they are stored on the web server. In other words, the content of a static site is fixed and does not change dynamically in response to user input or other external factors.&lt;/p&gt;
&lt;p&gt;Unlike dynamic websites, which rely on server-side processing to generate content on the fly, static sites are pre-built and require no server-side scripting or database access. This makes them faster, more secure, and less resource-intensive than dynamic sites, which can be more complex to build and maintain.&lt;/p&gt;
&lt;p&gt;Static sites are typically used for simple websites that don&amp;rsquo;t require advanced functionality or frequent updates, such as blogs, personal portfolios, or brochure-style websites. They can be hosted on any web server that supports static file hosting, including popular platforms like GitHub Pages, Netlify, or Amazon S3.&lt;/p&gt;
&lt;h2 id=&#34;amazon-s3&#34;&gt;Amazon S3&lt;/h2&gt;
&lt;p&gt;Amazon S3 (Simple Storage Service) is a cloud-based object storage service provided by Amazon Web Services (AWS). It allows users to store and retrieve large amounts of data from anywhere on the internet.&lt;/p&gt;
&lt;p&gt;Amazon S3 provides a simple interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. It is designed to be highly scalable, secure, and reliable. S3 is often used as a backend storage service for web and mobile applications, for data backup and archival purposes, and for hosting static websites.&lt;/p&gt;
&lt;h2 id=&#34;hugo&#34;&gt;Hugo&lt;/h2&gt;
&lt;p&gt;Hugo is an open-source static site generator written in the Go programming language (Golang). It is designed to be simple, fast, and flexible, allowing users to create static websites quickly and easily.&lt;/p&gt;
&lt;p&gt;Hugo takes Markdown files, templates, and a configuration file, and generates a static website in HTML, CSS, and JavaScript. It is based on a powerful template engine that allows users to customize the appearance and layout of their websites without having to write complex code.&lt;/p&gt;
&lt;h3 id=&#34;hosting-this-blog-in-aws-s3&#34;&gt;Hosting this blog in AWS S3&lt;/h3&gt;
&lt;p&gt;Since this site is just a blog which requires no dynamic content, it is a static site generated using hugo. While this site technically use Amazon Web Services it does not utilise the simple storage service (S3). In this blog post let us migrate the site to S3 bucket.&lt;/p&gt;
&lt;p&gt;You can migrate any static site to s3 bucket provided that you maintain the same directory structure inside the buckets. This is the directory and file structure of my blog and to host it on the &lt;code&gt;S3&lt;/code&gt; bucket, I just have to upload the files exactly in the same structure.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/statics3/files.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;First let us login to our aws management console, search &lt;code&gt;S3&lt;/code&gt; bucket among the services and then create a s3 bucket. We can leave most of the default options, but create a bucket name, choose the appropriate region for your site (closest to you probably), but make sure to disable &lt;code&gt;block all public access&lt;/code&gt;, but make sure to disable &lt;code&gt;block all public access&lt;/code&gt; and tick the acknowledgement. You can then create the bucket.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/statics3/createbucket.png&#34; alt=&#34;img&#34;&gt;
&lt;img src=&#34;/images/statics3/disableblock.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;After getting redireted to the bucket dashboard click on the newly created bucket.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/statics3/bucket.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now click upload and upload all the files, you can upload multiple files too.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/statics3/addfiles.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Wait for all files to be uploaded. I have slow internet speed so took me quite a while.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/statics3/uploading.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now that all the files have been uploaded go to the properties tab.&lt;/p&gt;
&lt;p&gt;Enable static website hosting.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/statics3/enablestatic.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Enter the index document and error document if present in your static site files and save changes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/statics3/enterindex.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now go to the permissions tab to edit a bucket policy. A bucket policy allows us to enable permissions so that our &lt;code&gt;S3&lt;/code&gt; bucket files can be accessed by the public.&lt;/p&gt;
&lt;p&gt;Add the following lines of json configuration to the policy and save it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Version&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2012-10-17&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Statement&amp;#34;&lt;/span&gt;: [
        {
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Sid&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AllowPublicAccess&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Effect&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Allow&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Principal&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Action&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s3:GetObject&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Resource&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;arn:aws:s3:::ngaihtech/*&amp;#34;&lt;/span&gt;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;sid: Way to identify your policy.&lt;/li&gt;
&lt;li&gt;Effect: It is either Allow or Deny.&lt;/li&gt;
&lt;li&gt;Principal: &amp;ldquo;*&amp;rdquo; is a wildcard to allow everyone.&lt;/li&gt;
&lt;li&gt;Action: &amp;ldquo;s3:GetObject&amp;rdquo; is a verb that allows to read the files from the s3 bucket.&lt;/li&gt;
&lt;li&gt;Resource: this is a way to identify your bucket, adding &amp;ldquo;/*&amp;rdquo; means giving access to all files inside the bucket.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/statics3/editpolicy.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now that we have given public access to the bucket files. Let us find the url of our bucket to access our hosted static site. Navigate to properties and scroll all the way to the bottom.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/statics3/properties.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Copy that and you can access your hosted static site in s3 using the url.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/statics3/web.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://ngaihtech.s3-website.eu-central-1.amazonaws.com&#34;&gt;http://ngaihtech.s3-website.eu-central-1.amazonaws.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The link won&amp;rsquo;t probably work anymore.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Now that we have hosted our static site, we can also purchase a domain name and make it point to the url of our s3 bucket.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
    </item>
    
  </channel>
</rss>
